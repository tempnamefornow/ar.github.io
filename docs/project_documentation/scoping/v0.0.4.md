# Project Scoping v0.0.4

*31st March 2023*



## Notes

- Downloaded the `gpt4all-lora-quantized.bin` to my compute instance using `wget https://the-eye.eu/public/AI/models/nomic-ai/gpt4all/gpt4all-lora-quantized.bin`. To get it to work, you need to copy the bin file to the `/chat` directory of the `nomic-ai/gpt4all` repo.
```bash
cp /home/azureuser/cloudfiles/code/Users/aaronward6210/libs/gpt4all/gpt4all-lora-quantized.bin 
/home/azureuser/cloudfiles/code/Users/aaronward6210/github/gpt4all/chat/
```
    - `cd chat`
    - `./gpt4all-lora-quantized-linux-x86`
    -  it takes a few minutes for the model to start up. There is also a little bit of output latency in the terminal, it generates token every ~half second
   <img src="../../../resources/images/project_documentation/scoping/gpt4all.png" style="height:400px; display: block; margin-right: auto; margin-left: auto;">


- Found another video talking about installing LLaMa and Alpaca. Will try this later. Here is the repo: [cocktailpeanut/dalai](https://github.com/cocktailpeanut/dalai)
    - You need `npm` installed to download the LLaMa models

- Langchain - Check out video https://www.youtube.com/watch?v=nE2skSRWTTs

<center>
<iframe width="560" height="315" src="https://www.youtube.com/embed/PyZPyqQqkLE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
</center>


- Thoughts: its actually insane how "democratized" these models have become in such a short amount of time. 